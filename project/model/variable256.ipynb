{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4868,
     "status": "ok",
     "timestamp": 1599295316162,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "D3apNnoc6Mnn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "# ここから自作\n",
    "import model\n",
    "import result\n",
    "import mode\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29932,
     "status": "ok",
     "timestamp": 1599295341242,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "DAmdrdrJws83"
   },
   "outputs": [],
   "source": [
    "# 時刻を表示してくれるようになるprint関数のwrapper\n",
    "def datePrint(*args, **kwargs):\n",
    "    from datetime import datetime\n",
    "    print(datetime.now().strftime('[%Y/%m/%d %H:%M:%S] '), end=\"\")\n",
    "    print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/04/07 14:57:55] loading pickle data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datePrint(\"loading pickle data\")\n",
    "input_val0 = pickle.load(open(\"../data/max_span100/input_test0.pkl\",\"rb\"))\n",
    "target_val0 = pickle.load(open(\"../data/max_span100/target_test0.pkl\",\"rb\")) #256のみ\n",
    "target_val0 = torch.flip(target_val0, dims=[1])\n",
    "input_train0 = pickle.load(open(\"../data/max_span100/input_train0.pkl\",\"rb\"))\n",
    "target_train0 = pickle.load(open(\"../data/max_span100/target_train0.pkl\",\"rb\")) #256以下\n",
    "target_train0 = torch.flip(target_train0, dims=[1])\n",
    "# input_val1 = pickle.load(open(\"../data/max_span100/input_test0.pkl\",\"rb\"))\n",
    "# target_val1 = pickle.load(open(\"../data/max_span100/target_test0.pkl\",\"rb\")) #256のみ\n",
    "# target_val1 = torch.flip(target_val1, dims=[1])\n",
    "# input_train1 = pickle.load(open(\"../data/max_span100/input_train0.pkl\",\"rb\"))\n",
    "# target_train1 = pickle.load(open(\"../data/max_span100/target_train0.pkl\",\"rb\")) #256以下\n",
    "# target_train1 = torch.flip(target_train1, dims=[1])\n",
    "\n",
    "input_all = torch.cat([input_train0, input_val0], dim=0)\n",
    "target_all = torch.cat([target_train0, target_val0], dim=0)\n",
    "dataset = model.Dataset(input_all, target_all)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [800000, 200000])\n",
    "del input_val0, target_val0, input_train0, target_train0\n",
    "\n",
    "# input_all = torch.cat([input_train0, input_val0, input_train1, input_val1], dim=0)\n",
    "# target_all = torch.cat([target_train0, target_val0, target_train1, target_val1], dim=0)\n",
    "# dataset = model.Dataset(input_all, target_all)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [1800000, 200000])\n",
    "\n",
    "# del input_val0, target_val0, input_train0, target_train0, input_val1, target_val1, input_train1, target_train1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def lambda_epoch(epoch):\n",
    "    # スケジューラの設定\n",
    "    max_epoch = 20\n",
    "    return math.pow((1-epoch/max_epoch), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4d55df15f3f947888809d424885dfe55",
      "a3ed74bd975e4e87955a0de33c520916",
      "8a817f317b5c42f592f130f576ee3063",
      "3c5b3c652eab41459f3779503ab44717",
      "de9d1fa4cee24559a816afe706b91081",
      "5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "16b98715895a42739075b7711e0ba437"
     ]
    },
    "colab_type": "code",
    "id": "FK5eCRTe6MoS",
    "outputId": "ae6267ee-0394-44aa-e1bd-0af90e62456d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/04/07 14:57:58] 0 layer 0 flag\n",
      "Epoch 1/20\n",
      "train Loss:2.8901675950050354 Timer:16091.802738666534\n",
      "val Loss:4.320832475662232 Timer:1300.6681745052338\n",
      "Epoch 2/20\n",
      "train Loss:2.8449122081947325 Timer:16093.79679608345\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "for n in [0]:\n",
    "    for x in [0]:\n",
    "        datePrint(n, 'layer', x, 'flag')\n",
    "        net = model.Fixed(num_layer=32, kernel_sizes=255, flag=False).to(device)\n",
    "        net.apply(model.weight_init) #重みの初期化適用\n",
    "\n",
    "        #ファインチューニング\n",
    "#         optimizer = optim.Adam([{'params': net.embedding.parameters(), 'lr': 5e-4},\n",
    "#                                 {'params': net.convs.parameters(), 'lr': 1e-4},\n",
    "#                                 {'params': net.mid.parameters(), 'lr': 5e-4},\n",
    "#                                 {'params': net.fc.parameters(), 'lr': 1e-3}], weight_decay=1e-6)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-6, eps=1e-5)\n",
    "\n",
    "        epochs = 20\n",
    "        criterion = nn.MSELoss().to(device)\n",
    "        \n",
    "        \n",
    "#         # 学習途中データ\n",
    "#         checkpoint = torch.load('max_span100.pth')\n",
    "#         net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#         epochs = checkpoint['epoch']\n",
    "#         loss = checkpoint['loss']\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)\n",
    "        train_loss_list, val_loss_list, data_all, target_all, output_all = mode.train(device, net, dataloaders_dict, criterion, optimizer, epochs)               \n",
    "        torch.save(net.state_dict(), 'max_span100_variable.pth')\n",
    "\n",
    "        result.learning_curve(train_loss_list, val_loss_list, epochs)\n",
    "        result.plot_result(np.array(target_all, dtype=object).reshape(-1), np.array(output_all, dtype=object).reshape(-1))\n",
    "        cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "        result.cor_hist(cor_list)\n",
    "        result.scatter_minmax(cor_list, loss_list, target_all, output_all)\n",
    "        result.visible_minmax(target_all, output_all, cor_list, loss_list)\n",
    "        result.show_base(data_all, cor_list, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_test = pickle.load(open(\"../data/test_sets/input_600_1000.pkl\",\"rb\"))\n",
    "# target_test = pickle.load(open(\"../data/test_sets/target_600_1000.pkl\",\"rb\"))\n",
    "input_test = pickle.load(open(\"../data/RF00156/input_RF00156.pkl\",\"rb\"))\n",
    "target_test = pickle.load(open(\"../data/RF00156/target_RF00156.pkl\",\"rb\"))\n",
    "target_test = torch.flip(target_test, dims=[1])\n",
    "datePrint(input_test.shape)\n",
    "datePrint(target_test.shape)\n",
    "if (input_test.shape[1]%256 != 0):\n",
    "    input_test = F.pad(input_test, (0, 256-input_test.shape[1]%256))\n",
    "    target_test = F.pad(target_test, (0, 252-target_test.shape[1]%256))\n",
    "if (input_test.shape[1]>256):\n",
    "    transform = True\n",
    "    division = (input_test.shape[1])//128 - 1\n",
    "    input_init = input_test\n",
    "    input_test = input_test.unfold(1, 256, 128).reshape(-1, 256)\n",
    "    target_test = target_test.unfold(1, 252, 128).reshape(-1, 252)\n",
    "else:\n",
    "    transform = False\n",
    "datePrint(input_test.shape)\n",
    "datePrint(target_test.shape)\n",
    "test_dataset = model.Dataset(input_test, target_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64,shuffle=False, num_workers=1)\n",
    "\n",
    "net = model.Fixed(num_layer=16, flag=False).to(device)\n",
    "net.load_state_dict(torch.load('max_span100.pth'))\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "start = time.time()\n",
    "test_loss, data_all, target_all, output_all = mode.test(device, net, test_dataloader, criterion) \n",
    "datePrint('finish prediction loss', test_loss)\n",
    "if (transform==True):\n",
    "    target_tmp = torch.tensor(target_all)\n",
    "    output_tmp = torch.tensor(output_all)\n",
    "    output_tmp = F.relu(output_tmp)\n",
    "    for n in range(division):\n",
    "        if (n==0):\n",
    "            target_all = target_tmp[n::division, :192]\n",
    "            output_all = output_tmp[n::division, :192]\n",
    "        elif (n==division-1):\n",
    "            target_all = torch.cat([target_all, target_tmp[n::division, 64:]], dim=1)\n",
    "            output_all = torch.cat([output_all, output_tmp[n::division, 64:]], dim=1)\n",
    "        else:\n",
    "            target_all = torch.cat([target_all, target_tmp[n::division, 64:192]], dim=1)\n",
    "            output_all = torch.cat([output_all, output_tmp[n::division, 64:192]], dim=1)\n",
    "    \n",
    "    data_all = input_init.numpy()\n",
    "    target_all = target_all.numpy()\n",
    "    output_all = output_all.numpy()\n",
    "finish = time.time()\n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3e')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datePrint('test_loss: {:.3f}'.format(test_loss))\n",
    "result.plot_result(np.array(target_all).reshape(-1), np.array(output_all).reshape(-1))\n",
    "cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "result.cor_hist(cor_list)\n",
    "result.scatter_minmax(cor_list, loss_list, target_all, output_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.visible_minmax(target_all, output_all, cor_list, loss_list)\n",
    "result.show_base(data_all, cor_list, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    result.visible_one(target_all, output_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "path = \"../data/mouse_data/seq3.fa\"\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name = seq_file[0]\n",
    "seq = ''.join(seq_file[1:]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4')\n",
    "input_seq = torch.Tensor(list(map(int, seq)))\n",
    "input_seq = torch.flip(input_seq, dims=[0])\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "out_length = len(input_seq[0])-4\n",
    "\n",
    "if (input_seq.shape[1]%256 != 0):\n",
    "    input_seq = F.pad(input_seq, (0, 256-input_seq.shape[1]%256))\n",
    "if (input_seq.shape[1]>256):\n",
    "    transform = True\n",
    "    division = (input_seq.shape[1])//128 - 1\n",
    "    input_init = input_seq\n",
    "    input_seq = input_seq.unfold(1, 256, 128).reshape(-1, 256)\n",
    "else:\n",
    "    transform = False\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "\n",
    "net = model.Fixed(num_layer=16, flag=False).to(device)\n",
    "net.load_state_dict(torch.load('256_finish.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, input_seq) \n",
    "\n",
    "if (transform==True):\n",
    "    output_tmp = torch.tensor(output_all)\n",
    "    for n in range(division):\n",
    "        if (n==0):\n",
    "            output_all = output_tmp[n::division, :192]\n",
    "        elif (n==division-1):\n",
    "            output_all = torch.cat([output_all, output_tmp[n::division, 64:]], dim=1)\n",
    "        else:\n",
    "            output_all = torch.cat([output_all, output_tmp[n::division, 64:192]], dim=1)\n",
    "    \n",
    "    data_all = input_init.numpy()\n",
    "#     output_all = torch.flip(output_all, dims=[1])\n",
    "    output_all = output_all.numpy()\n",
    "  \n",
    "import matplotlib.pyplot as plt\n",
    "max_length = output_all.shape[1]\n",
    "with open('../data/mouse_data/out3.txt', 'r') as f:\n",
    "        next(f)\n",
    "        acc = f.readlines()\n",
    "        acc_list = []\n",
    "        for i in range(len(acc)-1):\n",
    "                acc_list.append(re.findall(',(.*);', acc[i])[0])\n",
    "acc_list = [float(x) for x in acc_list]\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(out_length), acc_list, label='target', color='b')\n",
    "plt.plot(range(out_length), output_all[0][:out_length], label='output', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel('base position')\n",
    "plt.ylabel('accessibility')\n",
    "plt.title('one')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cor = np.corrcoef(acc_list, output_all[0][:out_length])\n",
    "mse = ((acc_list - output_all[0][:out_length])**2).mean(axis=0)\n",
    "print('cor', cor[0,1])\n",
    "print('mse', mse)\n",
    "\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/real_data/RF00156.fa\"\n",
    "\n",
    "start = time.time()\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name_list = []\n",
    "seq_list = torch.empty(0, 256)\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    name_list.append(seq_file[indexes[i]])\n",
    "    seq = ''.join(seq_file[indexes[i]+1:indexes[i+1]]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4').replace('N', '0')\n",
    "    seq = torch.Tensor(list(map(int, seq)))\n",
    "    seq = torch.flip(seq, dims=[0])\n",
    "    if (seq.shape[0]%256 != 0):\n",
    "        seq = F.pad(seq, (0, 256-seq.shape[0]%256))\n",
    "    seq = seq.unsqueeze(0)\n",
    "    seq_list = torch.cat([seq_list, seq], dim=0)\n",
    "\n",
    "\n",
    "# if (input_seq.shape[1]%256 != 0):\n",
    "#     input_seq = F.pad(input_seq, (0, 256-input_seq.shape[1]%256))\n",
    "# if (input_seq.shape[1]>256):\n",
    "#     transform = True\n",
    "#     division = (input_seq.shape[1])//128 - 1\n",
    "#     input_init = input_seq\n",
    "#     input_seq = input_seq.unfold(1, 256, 128).reshape(-1, 256)\n",
    "# else:\n",
    "#     transform = False\n",
    "# datePrint(input_seq.shape)\n",
    "# input_seq = input_seq.unsqueeze(0)\n",
    "# datePrint(input_seq.shape)\n",
    "\n",
    "seq_list = seq_list.unsqueeze(0)\n",
    "net = model.Fixed(num_layer=16, flag=False).to(device)\n",
    "net.load_state_dict(torch.load('256_finish.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, seq_list) \n",
    "# if (transform==True):\n",
    "#     output_tmp = torch.tensor(output_all)\n",
    "#     for n in range(division):\n",
    "#         if (n==0):\n",
    "#             output_all = output_tmp[n::division, :192]\n",
    "#         elif (n==division-1):\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:]], dim=1)\n",
    "#         else:\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:192]], dim=1)\n",
    "    \n",
    "#     data_all = input_init.numpy()\n",
    "#     output_all = output_all.numpy()\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample作成\n",
    "path = \"../data/RF01210/RF01210.fa\"\n",
    "\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    with open(f\"../data/RF01210/sample_{i}.txt\", mode=\"w\") as f:\n",
    "        f.write(seq_file[indexes[i]] + \"\\n\")\n",
    "        f.write(''.join(seq_file[indexes[i]+1:indexes[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# castしちゃう\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "for cond, cnt in ((\"train\", 500000), (\"test\", 500000)):\n",
    "    data_path = Path(f\"../data/makedata/{cond}\")\n",
    "    input_array = []\n",
    "    target_array = []\n",
    "    print(f\"reading {cond} files\")\n",
    "    for i in tqdm(range(cnt)):\n",
    "        input_path = data_path / f\"index/input_{i+1}.csv\"\n",
    "        target_path = data_path / f\"accessibility/target_{i+1}.csv\"\n",
    "\n",
    "        input_array.append(torch.Tensor(np.loadtxt(input_path, delimiter=\",\", dtype=np.float).astype(np.int)))\n",
    "        target_array.append(torch.Tensor(np.loadtxt(target_path, delimiter=\",\", dtype=np.float)))\n",
    "    print(f\"saving to input_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(input_array), open(f\"../data/input_{cond}.pkl\", 'wb'))\n",
    "        \n",
    "    print(f\"saving to target_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(target_array), open(f\"../data/target_{cond}.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iN96X35s5E8"
   },
   "outputs": [],
   "source": [
    "#メモリ確認\n",
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #10M以上のみ表示\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [
    {
     "file_id": "1ir0IJd6vc8l_FMQY9-YSFWxAQiIxZF6p",
     "timestamp": 1591723758584
    },
    {
     "file_id": "1cSw8tGp7_Atz1RUom-WbFEdJ1yVDgKCC",
     "timestamp": 1591700460320
    },
    {
     "file_id": "1-iiGLGF3JfbxpJ5cz5GyMTmbOMxhDH6D",
     "timestamp": 1591434878746
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16b98715895a42739075b7711e0ba437": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee0ab1bbc1e4cada381cdadbc3dc5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c5b3c652eab41459f3779503ab44717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b98715895a42739075b7711e0ba437",
      "placeholder": "​",
      "style": "IPY_MODEL_2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "value": " 0/50 [00:00&lt;?, ?it/s]"
     }
    },
    "4d55df15f3f947888809d424885dfe55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a817f317b5c42f592f130f576ee3063",
       "IPY_MODEL_3c5b3c652eab41459f3779503ab44717"
      ],
      "layout": "IPY_MODEL_a3ed74bd975e4e87955a0de33c520916"
     }
    },
    "5098cf4e3a6a4e5fb9daec2f6dc59c9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a817f317b5c42f592f130f576ee3063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de9d1fa4cee24559a816afe706b91081",
      "value": 0
     }
    },
    "a3ed74bd975e4e87955a0de33c520916": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de9d1fa4cee24559a816afe706b91081": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
