{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4868,
     "status": "ok",
     "timestamp": 1599295316162,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "D3apNnoc6Mnn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorch_memlab import MemReporter\n",
    "from torchinfo import summary\n",
    "# ここから自作\n",
    "import model\n",
    "import result\n",
    "import mode\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29932,
     "status": "ok",
     "timestamp": 1599295341242,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "DAmdrdrJws83"
   },
   "outputs": [],
   "source": [
    "# 時刻を表示してくれるようになるprint関数のwrapper\n",
    "def datePrint(*args, **kwargs):\n",
    "    from datetime import datetime\n",
    "    print(datetime.now().strftime('[%Y/%m/%d %H:%M:%S] '), end=\"\")\n",
    "    print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/10/12 01:25:35] loading pickle data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850ced7fdea04fc3962fc092cdbd675f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a4565fb3ed4e5e9f3851a841913f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datePrint(\"loading pickle data\")\n",
    "input_val0 = pickle.load(open(\"../data/max_span100_512/input_val0.pkl\",\"rb\"))\n",
    "target_val0 = pickle.load(open(\"../data/max_span100_512/target_val0.pkl\",\"rb\")) #512のみ\n",
    "target_val0 = torch.flip(target_val0, dims=[1])\n",
    "input_val1 = pickle.load(open(\"../data/max_span100_512/input_val1.pkl\",\"rb\"))\n",
    "target_val1 = pickle.load(open(\"../data/max_span100_512/target_val1.pkl\",\"rb\")) #512のみ\n",
    "target_val1 = torch.flip(target_val1, dims=[1])\n",
    "input_val2 = pickle.load(open(\"../data/max_span100_512/input_val2.pkl\",\"rb\"))\n",
    "target_val2 = pickle.load(open(\"../data/max_span100_512/target_val2.pkl\",\"rb\")) #512のみ\n",
    "target_val2 = torch.flip(target_val2, dims=[1])\n",
    "input_val3 = pickle.load(open(\"../data/max_span100_512/input_val3.pkl\",\"rb\"))\n",
    "target_val3 = pickle.load(open(\"../data/max_span100_512/target_val3.pkl\",\"rb\")) #512のみ\n",
    "target_val3 = torch.flip(target_val3, dims=[1])\n",
    "\n",
    "\n",
    "# input_all = torch.cat([input_val1, input_train2, input_val2, input_train3, input_val3], dim=0)\n",
    "# target_all = torch.cat([target_val1, target_train2, target_val2, target_train3, target_val3], dim=0)\n",
    "input_train = torch.cat([input_val0, input_val1, input_val2], dim=0)\n",
    "target_train = torch.cat([target_val0, target_val1, target_val2], dim=0)\n",
    "\n",
    "kmer_train = []\n",
    "for n in tqdm(range(len(input_train))):\n",
    "    tmp = []\n",
    "    for i in range(len(input_train[0])-2):\n",
    "        tmp.append(int(str(int(input_train[n][i]))+str(int(input_train[n][i+1]))+str(int(input_train[n][i+2]))))\n",
    "    kmer_train.append(tmp)\n",
    "kmer_train = torch.Tensor(kmer_train)\n",
    "\n",
    "kmer_val = []\n",
    "for n in tqdm(range(len(input_val3))):\n",
    "    tmp = []\n",
    "    for i in range(len(input_val3[0])-2):\n",
    "        tmp.append(int(str(int(input_val3[n][i]))+str(int(input_val3[n][i+1]))+str(int(input_val3[n][i+2]))))\n",
    "    kmer_val.append(tmp)\n",
    "kmer_val = torch.Tensor(kmer_val)\n",
    "\n",
    "train_dataset = model.Dataset(kmer_train, target_train)\n",
    "val_dataset = model.Dataset(kmer_val, target_val3)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [1800000, 200000])\n",
    "\n",
    "# del input_val0, target_val0, input_val1, target_val1, input_val2, target_val2, input_val3, target_val3\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def lambda_epoch(epoch):\n",
    "    # スケジューラの設定\n",
    "    max_epoch = 20\n",
    "    return math.pow((1-epoch/max_epoch), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4d55df15f3f947888809d424885dfe55",
      "a3ed74bd975e4e87955a0de33c520916",
      "8a817f317b5c42f592f130f576ee3063",
      "3c5b3c652eab41459f3779503ab44717",
      "de9d1fa4cee24559a816afe706b91081",
      "5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "16b98715895a42739075b7711e0ba437"
     ]
    },
    "colab_type": "code",
    "id": "FK5eCRTe6MoS",
    "outputId": "ae6267ee-0394-44aa-e1bd-0af90e62456d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "for n in [0]:\n",
    "    for x in [0]:\n",
    "        datePrint(n, 'nani', x, 'layer')\n",
    "        net = model.dilation1(num_layer=8, num_filters=128, kernel_sizes=5).to(device)\n",
    "        net.apply(model.weight_init) #重みの初期化適用\n",
    "#         print(summary(net, input_size=([batch_size, 512])))\n",
    "#         reporter = MemReporter(net)\n",
    "#         reporter.report()\n",
    "        #ファインチューニング\n",
    "#         optimizer = optim.Adam([{'params': net.embedding.parameters(), 'lr': 5e-4},\n",
    "#                                 {'params': net.convs.parameters(), 'lr': 1e-4},\n",
    "#                                 {'params': net.mid.parameters(), 'lr': 5e-4},\n",
    "#                                 {'params': net.fc.parameters(), 'lr': 1e-3}], weight_decay=1e-6)\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=1e-4, weight_decay=1e-6, eps=1e-6)\n",
    "        epochs = 20\n",
    "        criterion = nn.MSELoss().to(device)\n",
    "#         # 学習途中データ\n",
    "#         checkpoint = torch.load('max_span100.pth')\n",
    "#         net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#         epochs = checkpoint['epoch']\n",
    "#         loss = checkpoint['loss']\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)\n",
    "        train_loss_list, val_loss_list, data_all, target_all, output_all = mode.train(device, net, dataloaders_dict, criterion, optimizer, epochs)               \n",
    "        torch.save(net.state_dict(), '3mer.pth')\n",
    "    \n",
    "#         print(f'memory report')\n",
    "#         reporter.report()\n",
    "        \n",
    "        result.learning_curve(train_loss_list, val_loss_list, epochs)\n",
    "        result.plot_result(np.array(target_all, dtype=object).reshape(-1), np.array(output_all, dtype=object).reshape(-1))\n",
    "        cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "        result.loss_hist(loss_list)\n",
    "        result.cor_hist(cor_list)\n",
    "        loss_sort, cor_sort = result.sort_list(loss_list, cor_list)\n",
    "        dic = {'best loss': loss_sort[0],  'worst loss': loss_sort[-1], '10th bad loss': loss_sort[-10],'100th bad loss': loss_sort[-100],\n",
    "                  'best cor': cor_sort[-1], 'worst cor': cor_sort[0], '10th bad cor': cor_sort[9],'100th bad cor': cor_sort[99]} \n",
    "        for k, v in dic.items():\n",
    "            print(k)\n",
    "            result.visible_one(target_all, output_all, data_all, loss_list, cor_list, idx=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作りたてほやほやをinputとtargetに渡すよ\n",
    "input_array = []\n",
    "target_array = []\n",
    "for i in range(10):\n",
    "    input_path = f\"../data/makedata/val/index/input_{i+1}.csv\"\n",
    "    target_path = f\"../data/makedata/val/accessibility/target_{i+1}.csv\"\n",
    "    input_array.append(torch.Tensor(np.loadtxt(input_path, delimiter=\",\", dtype=np.float).astype(np.int)))\n",
    "    target_array.append(torch.Tensor(np.loadtxt(target_path, delimiter=\",\", dtype=np.float)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_test = pickle.load(open(\"../data/test_sets/input_600_1000.pkl\",\"rb\"))\n",
    "# target_test = pickle.load(open(\"../data/test_sets/target_600_1000.pkl\",\"rb\"))\n",
    "# input_test = pickle.load(open(\"../data/RF00156/input_RF00156.pkl\",\"rb\"))\n",
    "# target_test = pickle.load(open(\"../data/RF00156/target_RF00156.pkl\",\"rb\"))\n",
    "# input_test = torch.stack(input_array)\n",
    "# target_test = torch.stack(target_array)\n",
    "\n",
    "# target_test = torch.flip(target_test, dims=[1])\n",
    "\n",
    "input_test = pickle.load(open(\"../data/max_span100_512/input_val15.pkl\",\"rb\"))\n",
    "target_test = pickle.load(open(\"../data/max_span100_512/target_val15.pkl\",\"rb\")) #512のみ\n",
    "target_test = torch.flip(target_test, dims=[1])\n",
    "# input_test = input_test[0:10000] \n",
    "# target_test = target_test[0:10000]\n",
    "\n",
    "datePrint(input_test.shape)\n",
    "datePrint(target_test.shape)\n",
    "\n",
    "test_dataset = model.Dataset(input_test, target_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,shuffle=False, num_workers=1)\n",
    "\n",
    "net = model.dilation1(num_layer=16, num_filters=128, kernel_sizes=5).to(device)\n",
    "net.load_state_dict(torch.load('big_data.pth'))\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "start = time.time()\n",
    "test_loss, data_all, target_all, output_all = mode.test(device, net, test_dataloader, criterion) \n",
    "datePrint('finish prediction loss', test_loss)\n",
    "    \n",
    "# np.savetxt('accessibility_output.txt', output_all, fmt='%.3e')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_result(np.array(target_all, dtype=object).reshape(-1), np.array(output_all, dtype=object).reshape(-1))\n",
    "cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "result.loss_hist(loss_list)\n",
    "result.cor_hist(cor_list)\n",
    "loss_sort, cor_sort = result.sort_list(loss_list, cor_list)\n",
    "dic = {'best loss': loss_sort[0],  'worst loss': loss_sort[-100], 'best cor': cor_sort[-1], 'worst cor': cor_sort[100]} \n",
    "for k, v in dic.items():\n",
    "    print(k)\n",
    "    result.visible_one(target_all, output_all, data_all, loss_list, cor_list, idx=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_target, loss_output, loss_data, cor_target, cor_output, cor_data = result.remake_bad(target_all, output_all, data_all, loss_sort, cor_sort, length=1000)\n",
    "result.plot_result(np.array(loss_target, dtype=object).reshape(-1), np.array(loss_output, dtype=object).reshape(-1))\n",
    "result.plot_result(np.array(cor_target, dtype=object).reshape(-1), np.array(cor_output, dtype=object).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diff(data_all):\n",
    "    diff_list = []\n",
    "    for i in data_all:\n",
    "        count_A, count_U, count_G, count_C = 0, 0, 0, 0\n",
    "        count_A += np.count_nonzero(i==1)\n",
    "        count_U += np.count_nonzero(i==2)\n",
    "        count_G += np.count_nonzero(i==3)\n",
    "        count_C += np.count_nonzero(i==4)\n",
    "#         diff = abs(count_A-len(i)/4) + abs(count_U-len(i)/4) + abs(count_G-len(i)/4) + abs(count_C-len(i)/4)\n",
    "        diff = count_G-len(i)/4\n",
    "        diff_list.append(diff)\n",
    "\n",
    "    return diff_list\n",
    "\n",
    "_, loss_list = result.cal_indicators(loss_target, loss_output)\n",
    "diff_list = count_diff(loss_data)\n",
    "result.heat_scatter(diff_list, loss_list)\n",
    "\n",
    "cor_list, _ = result.cal_indicators(cor_target, cor_output)\n",
    "diff_list = count_diff(cor_data)\n",
    "result.heat_scatter(diff_list, cor_list)\n",
    "\n",
    "# diff_list = count_diff(data_all)\n",
    "# result.heat_scatter(diff_list, loss_list)\n",
    "# result.heat_scatter(diff_list, cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = result.count_diff(data_all)\n",
    "result.heat_scatter(diff_list, loss_list)\n",
    "result.heat_scatter(diff_list, cor_list)\n",
    "\n",
    "_, loss_bad = result.cal_indicators(loss_target, loss_output)\n",
    "diff_list = result.count_diff(loss_data)\n",
    "result.heat_scatter(diff_list, loss_bad)\n",
    "\n",
    "cor_bad, _ = result.cal_indicators(cor_target, cor_output)\n",
    "diff_list = result.count_diff(cor_data)\n",
    "result.heat_scatter(diff_list, cor_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "path = \"../data/human_data/seq7.fa\"\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name = seq_file[0]\n",
    "seq = ''.join(seq_file[1:]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4')\n",
    "input_seq = torch.Tensor(list(map(int, seq)))\n",
    "input_seq = torch.flip(input_seq, dims=[0])\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "out_length = len(input_seq[0])-4\n",
    "\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "\n",
    "net = model.dilation1(num_layer=16, num_filters=128, kernel_sizes=5).to(device)\n",
    "net.load_state_dict(torch.load('big_data.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, input_seq) \n",
    "\n",
    "  \n",
    "import matplotlib.pyplot as plt\n",
    "max_length = output_all.shape[1]\n",
    "with open('../data/human_data/out7.txt', 'r') as f:\n",
    "        next(f)\n",
    "        acc = f.readlines()\n",
    "        acc_list = []\n",
    "        for i in range(len(acc)-1):\n",
    "                acc_list.append(re.findall(',(.*);', acc[i])[0])\n",
    "acc_list = [float(x) for x in acc_list]\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(out_length), acc_list, label='target', color='b')\n",
    "plt.plot(range(out_length), output_all[0][:out_length], label='output', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel('base position')\n",
    "plt.ylabel('accessibility')\n",
    "plt.title('one')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cor = np.corrcoef(acc_list, output_all[0][:out_length])\n",
    "mse = ((acc_list - output_all[0][:out_length])**2).mean(axis=0)\n",
    "print('cor', cor[0,1])\n",
    "print('mse', mse)\n",
    "\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/real_data/RF00156.fa\"\n",
    "\n",
    "start = time.time()\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name_list = []\n",
    "seq_list = torch.empty(0, 256)\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    name_list.append(seq_file[indexes[i]])\n",
    "    seq = ''.join(seq_file[indexes[i]+1:indexes[i+1]]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4').replace('N', '0')\n",
    "    seq = torch.Tensor(list(map(int, seq)))\n",
    "    seq = torch.flip(seq, dims=[0])\n",
    "    if (seq.shape[0]%256 != 0):\n",
    "        seq = F.pad(seq, (0, 256-seq.shape[0]%256))\n",
    "    seq = seq.unsqueeze(0)\n",
    "    seq_list = torch.cat([seq_list, seq], dim=0)\n",
    "\n",
    "\n",
    "# if (input_seq.shape[1]%256 != 0):\n",
    "#     input_seq = F.pad(input_seq, (0, 256-input_seq.shape[1]%256))\n",
    "# if (input_seq.shape[1]>256):\n",
    "#     transform = True\n",
    "#     division = (input_seq.shape[1])//128 - 1\n",
    "#     input_init = input_seq\n",
    "#     input_seq = input_seq.unfold(1, 256, 128).reshape(-1, 256)\n",
    "# else:\n",
    "#     transform = False\n",
    "# datePrint(input_seq.shape)\n",
    "# input_seq = input_seq.unsqueeze(0)\n",
    "# datePrint(input_seq.shape)\n",
    "\n",
    "seq_list = seq_list.unsqueeze(0)\n",
    "net = model.Variable(num_layer=16, kernel_sizes=33, flag=False).to(device)\n",
    "net.load_state_dict(torch.load('max_span20.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, seq_list) \n",
    "# if (transform==True):\n",
    "#     output_tmp = torch.tensor(output_all)\n",
    "#     for n in range(division):\n",
    "#         if (n==0):\n",
    "#             output_all = output_tmp[n::division, :192]\n",
    "#         elif (n==division-1):\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:]], dim=1)\n",
    "#         else:\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:192]], dim=1)\n",
    "    \n",
    "#     data_all = input_init.numpy()\n",
    "#     output_all = output_all.numpy()\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample作成\n",
    "path = \"../data/RF01210/RF01210.fa\"\n",
    "\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    with open(f\"../data/RF01210/sample_{i}.txt\", mode=\"w\") as f:\n",
    "        f.write(seq_file[indexes[i]] + \"\\n\")\n",
    "        f.write(''.join(seq_file[indexes[i]+1:indexes[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# castしちゃう\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "for cond, cnt in ((\"train\", 500000), (\"test\", 500000)):\n",
    "    data_path = Path(f\"../data/makedata/{cond}\")\n",
    "    input_array = []\n",
    "    target_array = []\n",
    "    print(f\"reading {cond} files\")\n",
    "    for i in tqdm(range(cnt)):\n",
    "        input_path = data_path / f\"index/input_{i+1}.csv\"\n",
    "        target_path = data_path / f\"accessibility/target_{i+1}.csv\"\n",
    "\n",
    "        input_array.append(torch.Tensor(np.loadtxt(input_path, delimiter=\",\", dtype=np.float).astype(np.int)))\n",
    "        target_array.append(torch.Tensor(np.loadtxt(target_path, delimiter=\",\", dtype=np.float)))\n",
    "    print(f\"saving to input_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(input_array), open(f\"../data/input_{cond}.pkl\", 'wb'))\n",
    "        \n",
    "    print(f\"saving to target_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(target_array), open(f\"../data/target_{cond}.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iN96X35s5E8"
   },
   "outputs": [],
   "source": [
    "#メモリ確認\n",
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #10M以上のみ表示\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [
    {
     "file_id": "1ir0IJd6vc8l_FMQY9-YSFWxAQiIxZF6p",
     "timestamp": 1591723758584
    },
    {
     "file_id": "1cSw8tGp7_Atz1RUom-WbFEdJ1yVDgKCC",
     "timestamp": 1591700460320
    },
    {
     "file_id": "1-iiGLGF3JfbxpJ5cz5GyMTmbOMxhDH6D",
     "timestamp": 1591434878746
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16b98715895a42739075b7711e0ba437": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee0ab1bbc1e4cada381cdadbc3dc5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c5b3c652eab41459f3779503ab44717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b98715895a42739075b7711e0ba437",
      "placeholder": "​",
      "style": "IPY_MODEL_2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "value": " 0/50 [00:00&lt;?, ?it/s]"
     }
    },
    "4d55df15f3f947888809d424885dfe55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a817f317b5c42f592f130f576ee3063",
       "IPY_MODEL_3c5b3c652eab41459f3779503ab44717"
      ],
      "layout": "IPY_MODEL_a3ed74bd975e4e87955a0de33c520916"
     }
    },
    "5098cf4e3a6a4e5fb9daec2f6dc59c9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a817f317b5c42f592f130f576ee3063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de9d1fa4cee24559a816afe706b91081",
      "value": 0
     }
    },
    "a3ed74bd975e4e87955a0de33c520916": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de9d1fa4cee24559a816afe706b91081": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
