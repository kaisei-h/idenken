{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4868,
     "status": "ok",
     "timestamp": 1599295316162,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "D3apNnoc6Mnn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "import collections\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorch_memlab import MemReporter\n",
    "from torchinfo import summary\n",
    "# ここから自作\n",
    "import model\n",
    "import result\n",
    "import mode\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        out_data = self.data[index]\n",
    "        out_target = self.target[index]\n",
    "        \n",
    "        return out_data, out_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29932,
     "status": "ok",
     "timestamp": 1599295341242,
     "user": {
      "displayName": "Kaisei Hara",
      "photoUrl": "",
      "userId": "00093271953957882617"
     },
     "user_tz": -540
    },
    "id": "DAmdrdrJws83"
   },
   "outputs": [],
   "source": [
    "# 時刻を表示してくれるようになるprint関数のwrapper\n",
    "def datePrint(*args, **kwargs):\n",
    "    from datetime import datetime\n",
    "    print(datetime.now().strftime('[%Y/%m/%d %H:%M:%S] '), end=\"\")\n",
    "    print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        tokens = reader.readlines()\n",
    "    for index, token in enumerate(tokens):\n",
    "        token = token.rstrip(\"\\n\")\n",
    "        vocab[token] = index\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bert仕様から，オリジナル仕様に加工してますね\n",
    "# df = pd.read_table('../data/make/forbert/dev.tsv')\n",
    "# dev = df['sequence'].str.split(' ', expand=True).replace(vocab).drop(columns=508)\n",
    "# dev = torch.tensor(dev.values).to(torch.float)\n",
    "# print(dev.shape)\n",
    "# pickle.dump(dev, open(f\"../data/make/forbert/dev.pkl\", \"wb\"))\n",
    "\n",
    "# df = pd.read_table('../data/make/forbert/train.tsv')\n",
    "# train = df['sequence'].str.split(' ', expand=True).replace(vocab)\n",
    "# print(train)\n",
    "# train = train.drop(columns=508)\n",
    "# train = torch.tensor(train.values).to(torch.float)\n",
    "# print(train.shape)\n",
    "# pickle.dump(train, open(f\"../data/make/forbert/train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kmer読み込み\n",
    "# vocab = load_vocab(\"../data/make/forbert/vocab.txt\")\n",
    "\n",
    "# dev = pickle.load(open(\"../data/make/forbert/dev.pkl\",\"rb\"))\n",
    "# print(dev.shape)\n",
    "# train = pickle.load(open(\"../data/make/forbert/train.pkl\",\"rb\"))\n",
    "# print(train.shape)\n",
    "\n",
    "# target_dev = torch.tensor(pickle.load(open(\"../data/make/forbert/target_dev.pkl\",\"rb\")))\n",
    "# target_dev = torch.flip(target_dev, dims=[1]).to(torch.float)\n",
    "# print(target_dev.shape)\n",
    "\n",
    "# target_train = torch.tensor(pickle.load(open(\"../data/make/forbert/target_train.pkl\",\"rb\")))\n",
    "# target_train = torch.flip(target_train, dims=[1]).to(torch.float)\n",
    "# print(target_train.shape)\n",
    "\n",
    "# input_all = torch.cat([train, dev], dim=0)\n",
    "# target_all = torch.cat([target_train, target_dev], dim=0)\n",
    "# print(input_all.shape)\n",
    "# print(target_all.shape)\n",
    "\n",
    "# dataset = model.Dataset(input_all, target_all)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [180000, 20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/03/14 08:01:48] loading pickle data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "datePrint(\"loading pickle data\")\n",
    "input1 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/seq_1.pkl\",\"rb\")))\n",
    "target1 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/target_1.pkl\",\"rb\"))).float()\n",
    "target1 = torch.flip(target1, dims=[1])\n",
    "input2 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/seq_2.pkl\",\"rb\")))\n",
    "target2 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/target_2.pkl\",\"rb\"))).float()\n",
    "target2 = torch.flip(target2, dims=[1])\n",
    "input3 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/seq_3.pkl\",\"rb\")))\n",
    "target3 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/target_3.pkl\",\"rb\"))).float()\n",
    "target3 = torch.flip(target3, dims=[1])\n",
    "# input4 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/seq_4.pkl\",\"rb\")))\n",
    "# target4 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/target_4.pkl\",\"rb\"))).float()\n",
    "# target4 = torch.flip(target4, dims=[1])\n",
    "# input5 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/seq_5.pkl\",\"rb\")))\n",
    "# target5 = torch.tensor(pickle.load(open(\"../data/r-make/maxspan100/target_5.pkl\",\"rb\"))).float()\n",
    "# target5 = torch.flip(target5, dims=[1])\n",
    "\n",
    "input_all = torch.cat([input1, input2, input3], dim=0)\n",
    "target_all = torch.cat([target1, target2, target3], dim=0)\n",
    "\n",
    "dataset = model.Dataset(input_all, target_all)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [1200000, 300000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# costom loss軍団\n",
    "    \n",
    "class CosineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineLoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return torch.sum(1 - nn.functional.cosine_similarity(outputs, targets, dim=-1, eps=1e-6))\n",
    "\n",
    "class HyperbolicLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HyperbolicLoss, self).__init__()\n",
    "\n",
    "    def forward(self, u, v, epsilon=1e-7):\n",
    "        sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
    "        squnorm = torch.sum(u ** 2, dim=-1)\n",
    "        sqvnorm = torch.sum(v ** 2, dim=-1)\n",
    "        x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + epsilon\n",
    "        z = torch.sqrt(x ** 2 - 1)\n",
    "        return torch.sum(z)\n",
    "\n",
    "# from geomstats.geometry.poincare_ball import PoincareBall\n",
    "# class PoincareBallLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(PoincareBallLoss, self).__init__()\n",
    "        \n",
    "#     def forward(self, output, target):\n",
    "#         output = output.cpu().detach().numpy()\n",
    "#         target = target.cpu().detach().numpy()\n",
    "#         return float(PoincareBall(dim=8).metric.dist(output[0], target[0]))\n",
    "\n",
    "\n",
    "losses = [nn.MSELoss]\n",
    "lrs = [1e-4, 1e-5, 1e-3]\n",
    "# opts = [optim.Adam, optim.RMSprop, optim.Adamax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv1DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1):\n",
    "        super(conv1DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        output = self.batchnorm(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "class conv1DBatchNormMish(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1):\n",
    "        super(conv1DBatchNormMish, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm1d(out_channels)\n",
    "        self.mish = nn.Mish(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        output = self.mish(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class scSE(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super(scSE, self).__init__()\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels//reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(channels//reduction, channels, bias=False)\n",
    "        \n",
    "        self.conv = nn.Conv1d(channels, 1, kernel_size=1)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channel, _ = x.size()\n",
    "        c = self.gap(x).view(batch, channel)\n",
    "        c = self.sig(self.fc2(F.relu(self.fc1(c)))).view(batch, channel, 1)\n",
    "        c = x * c\n",
    "        \n",
    "        s = self.sig(self.conv(x))\n",
    "        s = x * s\n",
    "        return c + s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable(nn.Module):\n",
    "    def __init__(self, emb_dim=128, num_layer=8, num_filters=128, kernel_sizes=5):\n",
    "        super(Variable, self).__init__()\n",
    "        self.filter = num_filters\n",
    "        self.embedding = nn.Embedding(6, emb_dim)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv1DBatchNormMish(in_channels=emb_dim, out_channels=num_filters,\n",
    "                         kernel_size=kernel_sizes, padding=kernel_sizes//2, stride=1))\n",
    "        self.convs.append(scSE(channels=num_filters))\n",
    "        for i in range(num_layer):\n",
    "            self.convs.append(conv1DBatchNormMish(in_channels=num_filters, out_channels=num_filters,\n",
    "                                                    kernel_size=kernel_sizes, padding=(kernel_sizes//2)*1, dilation=1))\n",
    "            self.convs.append(conv1DBatchNormMish(in_channels=num_filters, out_channels=num_filters,\n",
    "                                                    kernel_size=kernel_sizes, padding=(kernel_sizes//2)*3, dilation=3))\n",
    "            self.convs.append(conv1DBatchNormMish(in_channels=num_filters, out_channels=num_filters,\n",
    "                                                    kernel_size=kernel_sizes, padding=(kernel_sizes//2)*1, dilation=1))\n",
    "            self.convs.append(conv1DBatchNormMish(in_channels=num_filters, out_channels=num_filters,\n",
    "                                                    kernel_size=kernel_sizes, padding=(kernel_sizes//2)*5, dilation=5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.convs.append(conv1DBatchNormMish(in_channels=num_filters, out_channels=num_filters, kernel_size=kernel_sizes, padding=kernel_sizes//2))\n",
    "        self.convs.append(scSE(channels=num_filters))\n",
    "        self.convs.append(conv1DBatchNorm(in_channels=num_filters, out_channels=1, kernel_size=5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        for i, l in enumerate(self.convs):\n",
    "            x = l(x)\n",
    "            if type(x) is tuple:\n",
    "                x = x[0]\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return x\n",
    "\n",
    "class Trans(nn.Module):\n",
    "    def __init__(self, emb_dim=128, num_filters=128):\n",
    "        super(Trans, self).__init__()\n",
    "        self.filter = num_filters\n",
    "        self.embedding = nn.Embedding(6, emb_dim)\n",
    "        self.conv = conv1DBatchNormMish(in_channels=emb_dim, out_channels=1, kernel_size=5)\n",
    "        self.transformer = nn.Transformer(d_model=508, nhead=4, batch_first=True)\n",
    "\n",
    "    def forward(self, data, target):\n",
    "        data = self.embedding(data.long())\n",
    "        data = torch.transpose(data, 1, 2)\n",
    "        data = self.conv(data)\n",
    "        target = target.reshape(-1, 1, 508)\n",
    "        \n",
    "        output = self.transformer(data, target)\n",
    "\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        return output\n",
    "    \n",
    "class TransEnc(nn.Module):\n",
    "    def __init__(self, emb_dim=256, num_filters=128):\n",
    "        super(TransEnc, self).__init__()\n",
    "        self.filter = num_filters\n",
    "        self.embedding = nn.Embedding(6, emb_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
    "        self.conv = conv1DBatchNorm(in_channels=emb_dim, out_channels=1, kernel_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long()) #(batch, length, emb)\n",
    "        x = torch.transpose(x, 1, 2) #(batch, emb=256, length=512)\n",
    "        x = self.transformer(x)\n",
    "        x = self.conv(x)\n",
    "        \n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4d55df15f3f947888809d424885dfe55",
      "a3ed74bd975e4e87955a0de33c520916",
      "8a817f317b5c42f592f130f576ee3063",
      "3c5b3c652eab41459f3779503ab44717",
      "de9d1fa4cee24559a816afe706b91081",
      "5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "16b98715895a42739075b7711e0ba437"
     ]
    },
    "colab_type": "code",
    "id": "FK5eCRTe6MoS",
    "outputId": "ae6267ee-0394-44aa-e1bd-0af90e62456d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: RAdam (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 1/10\n",
      "val Loss:13.1027 Timer:93.9264\n",
      "Epoch 2/10\n",
      "train Loss:9.0973 Timer:1126.0053\n",
      "val Loss:6.9117 Timer:90.5646\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "for loss in losses:\n",
    "    for lr in lrs:\n",
    "        net = TransEnc().to(device)\n",
    "#         net = model.Variable(num_layer=8, num_filters=128, kernel_sizes=5).to(device)\n",
    "        net.apply(model.weight_init) #重みの初期化適用\n",
    "        #         print(summary(net, input_size=([batch_size, 512])))\n",
    "        #         reporter = MemReporter(net)\n",
    "        #         reporter.report()\n",
    "        #ファインチューニング\n",
    "        #         optimizer = optim.Adam([{'params': net.embedding.parameters(), 'lr': 5e-4},\n",
    "        #                                 {'params': net.convs.parameters(), 'lr': 1e-4},\n",
    "        #                                 {'params': net.mid.parameters(), 'lr': 5e-4},\n",
    "        #                                 {'params': net.fc.parameters(), 'lr': 1e-3}], weight_decay=1e-6)\n",
    "        optimizer = torch.optim.RAdam(net.parameters(), lr=lr)\n",
    "        print(f'optimizer: {optimizer}')\n",
    "        epochs = 10\n",
    "        criterion = loss().to(device)\n",
    "        #         # 学習途中データ\n",
    "        #         checkpoint = torch.load('max_span100.pth')\n",
    "        #         net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        #         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #         epochs = checkpoint['epoch']\n",
    "        #         loss = checkpoint['loss']\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "        train_loss_list, val_loss_list, data_all, target_all, output_all = mode.train(device, net, dataloaders_dict, criterion, optimizer, epochs, scheduler)               \n",
    "        torch.save(net.state_dict(), 'tmp.pth')\n",
    "\n",
    "        #         print(f'memory report')\n",
    "        #         reporter.report()\n",
    "\n",
    "    #     result.learning_curve(train_loss_list, val_loss_list, epochs[1:])\n",
    "    #     result.plot_result(np.array(target_all, dtype=object).reshape(-1), np.array(output_all, dtype=object).reshape(-1))\n",
    "        cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "        result.loss_hist(loss_list)\n",
    "        result.cor_hist(cor_list)\n",
    "    #     loss_sort, cor_sort = result.sort_list(loss_list, cor_list)\n",
    "    #     dic = {'best loss': loss_sort[0],  'worst loss': loss_sort[-1], '10th bad loss': loss_sort[-10],'100th bad loss': loss_sort[-100],\n",
    "    #               'best cor': cor_sort[-1], 'worst cor': cor_sort[0], '10th bad cor': cor_sort[9],'100th bad cor': cor_sort[99]} \n",
    "    #     for k, v in dic.items():\n",
    "    #         print(k)\n",
    "    #         result.visible_one(target_all, output_all, data_all, loss_list, cor_list, idx=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 作りたてほやほやをinputとtargetに渡すよ\n",
    "# input_array = []\n",
    "# target_array = []\n",
    "# for i in range(10):\n",
    "#     input_path = f\"../data/makedata/val/index/input_{i+1}.csv\"\n",
    "#     target_path = f\"../data/makedata/val/accessibility/target_{i+1}.csv\"\n",
    "#     input_array.append(torch.Tensor(np.loadtxt(input_path, delimiter=\",\", dtype=np.float).astype(np.int)))\n",
    "#     target_array.append(torch.Tensor(np.loadtxt(target_path, delimiter=\",\", dtype=np.float)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_test = pickle.load(open(\"../data/test_sets/input_600_1000.pkl\",\"rb\"))\n",
    "# target_test = pickle.load(open(\"../data/test_sets/target_600_1000.pkl\",\"rb\"))\n",
    "# input_test = pickle.load(open(\"../data/RF00156/input_RF00156.pkl\",\"rb\"))\n",
    "# target_test = pickle.load(open(\"../data/RF00156/target_RF00156.pkl\",\"rb\"))\n",
    "# input_test = torch.stack(input_array)\n",
    "# target_test = torch.stack(target_array)\n",
    "\n",
    "# target_test = torch.flip(target_test, dims=[1])\n",
    "\n",
    "input_test = pickle.load(open(\"../data/max_span100_512/input_val15.pkl\",\"rb\"))\n",
    "target_test = pickle.load(open(\"../data/max_span100_512/target_val15.pkl\",\"rb\")) #512のみ\n",
    "target_test = torch.flip(target_test, dims=[1])\n",
    "# input_test = input_test[0:10000] \n",
    "# target_test = target_test[0:10000]\n",
    "\n",
    "datePrint(input_test.shape)\n",
    "datePrint(target_test.shape)\n",
    "\n",
    "test_dataset = model.Dataset(input_test, target_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,shuffle=False, num_workers=1)\n",
    "\n",
    "net = model.dilation1(num_layer=16, num_filters=128, kernel_sizes=5).to(device)\n",
    "net.load_state_dict(torch.load('big_data.pth'))\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "start = time.time()\n",
    "test_loss, data_all, target_all, output_all = mode.test(device, net, test_dataloader, criterion) \n",
    "datePrint('finish prediction loss', test_loss)\n",
    "    \n",
    "# np.savetxt('accessibility_output.txt', output_all, fmt='%.3e')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_result(np.array(target_all, dtype=object).reshape(-1), np.array(output_all, dtype=object).reshape(-1))\n",
    "cor_list, loss_list = result.cal_indicators(target_all, output_all)\n",
    "result.loss_hist(loss_list)\n",
    "result.cor_hist(cor_list)\n",
    "loss_sort, cor_sort = result.sort_list(loss_list, cor_list)\n",
    "dic = {'best loss': loss_sort[0],  'worst loss': loss_sort[-100], 'best cor': cor_sort[-1], 'worst cor': cor_sort[100]} \n",
    "for k, v in dic.items():\n",
    "    print(k)\n",
    "    result.visible_one(target_all, output_all, data_all, loss_list, cor_list, idx=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_target, loss_output, loss_data, cor_target, cor_output, cor_data = result.remake_bad(target_all, output_all, data_all, loss_sort, cor_sort, length=1000)\n",
    "result.plot_result(np.array(loss_target, dtype=object).reshape(-1), np.array(loss_output, dtype=object).reshape(-1))\n",
    "result.plot_result(np.array(cor_target, dtype=object).reshape(-1), np.array(cor_output, dtype=object).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diff(data_all):\n",
    "    diff_list = []\n",
    "    for i in data_all:\n",
    "        count_A, count_U, count_G, count_C = 0, 0, 0, 0\n",
    "        count_A += np.count_nonzero(i==1)\n",
    "        count_U += np.count_nonzero(i==2)\n",
    "        count_G += np.count_nonzero(i==3)\n",
    "        count_C += np.count_nonzero(i==4)\n",
    "#         diff = abs(count_A-len(i)/4) + abs(count_U-len(i)/4) + abs(count_G-len(i)/4) + abs(count_C-len(i)/4)\n",
    "        diff = count_G-len(i)/4\n",
    "        diff_list.append(diff)\n",
    "\n",
    "    return diff_list\n",
    "\n",
    "_, loss_list = result.cal_indicators(loss_target, loss_output)\n",
    "diff_list = count_diff(loss_data)\n",
    "result.heat_scatter(diff_list, loss_list)\n",
    "\n",
    "cor_list, _ = result.cal_indicators(cor_target, cor_output)\n",
    "diff_list = count_diff(cor_data)\n",
    "result.heat_scatter(diff_list, cor_list)\n",
    "\n",
    "# diff_list = count_diff(data_all)\n",
    "# result.heat_scatter(diff_list, loss_list)\n",
    "# result.heat_scatter(diff_list, cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = result.count_diff(data_all)\n",
    "result.heat_scatter(diff_list, loss_list)\n",
    "result.heat_scatter(diff_list, cor_list)\n",
    "\n",
    "_, loss_bad = result.cal_indicators(loss_target, loss_output)\n",
    "diff_list = result.count_diff(loss_data)\n",
    "result.heat_scatter(diff_list, loss_bad)\n",
    "\n",
    "cor_bad, _ = result.cal_indicators(cor_target, cor_output)\n",
    "diff_list = result.count_diff(cor_data)\n",
    "result.heat_scatter(diff_list, cor_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "path = \"../data/human_data/seq7.fa\"\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name = seq_file[0]\n",
    "seq = ''.join(seq_file[1:]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4')\n",
    "input_seq = torch.Tensor(list(map(int, seq)))\n",
    "input_seq = torch.flip(input_seq, dims=[0])\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "out_length = len(input_seq[0])-4\n",
    "\n",
    "input_seq = input_seq.unsqueeze(0)\n",
    "\n",
    "net = model.dilation1(num_layer=16, num_filters=128, kernel_sizes=5).to(device)\n",
    "net.load_state_dict(torch.load('big_data.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, input_seq) \n",
    "\n",
    "  \n",
    "import matplotlib.pyplot as plt\n",
    "max_length = output_all.shape[1]\n",
    "with open('../data/human_data/out7.txt', 'r') as f:\n",
    "        next(f)\n",
    "        acc = f.readlines()\n",
    "        acc_list = []\n",
    "        for i in range(len(acc)-1):\n",
    "                acc_list.append(re.findall(',(.*);', acc[i])[0])\n",
    "acc_list = [float(x) for x in acc_list]\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(out_length), acc_list, label='target', color='b')\n",
    "plt.plot(range(out_length), output_all[0][:out_length], label='output', color='r')\n",
    "plt.legend()\n",
    "plt.xlabel('base position')\n",
    "plt.ylabel('accessibility')\n",
    "plt.title('one')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cor = np.corrcoef(acc_list, output_all[0][:out_length])\n",
    "mse = ((acc_list - output_all[0][:out_length])**2).mean(axis=0)\n",
    "print('cor', cor[0,1])\n",
    "print('mse', mse)\n",
    "\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/real_data/RF00156.fa\"\n",
    "\n",
    "start = time.time()\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "name_list = []\n",
    "seq_list = torch.empty(0, 256)\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    name_list.append(seq_file[indexes[i]])\n",
    "    seq = ''.join(seq_file[indexes[i]+1:indexes[i+1]]).replace('A', '1').replace('T', '2').replace('U', '2').replace('G', '3').replace('C', '4').replace('N', '0')\n",
    "    seq = torch.Tensor(list(map(int, seq)))\n",
    "    seq = torch.flip(seq, dims=[0])\n",
    "    if (seq.shape[0]%256 != 0):\n",
    "        seq = F.pad(seq, (0, 256-seq.shape[0]%256))\n",
    "    seq = seq.unsqueeze(0)\n",
    "    seq_list = torch.cat([seq_list, seq], dim=0)\n",
    "\n",
    "\n",
    "# if (input_seq.shape[1]%256 != 0):\n",
    "#     input_seq = F.pad(input_seq, (0, 256-input_seq.shape[1]%256))\n",
    "# if (input_seq.shape[1]>256):\n",
    "#     transform = True\n",
    "#     division = (input_seq.shape[1])//128 - 1\n",
    "#     input_init = input_seq\n",
    "#     input_seq = input_seq.unfold(1, 256, 128).reshape(-1, 256)\n",
    "# else:\n",
    "#     transform = False\n",
    "# datePrint(input_seq.shape)\n",
    "# input_seq = input_seq.unsqueeze(0)\n",
    "# datePrint(input_seq.shape)\n",
    "\n",
    "seq_list = seq_list.unsqueeze(0)\n",
    "net = model.Variable(num_layer=16, kernel_sizes=33, flag=False).to(device)\n",
    "net.load_state_dict(torch.load('max_span20.pth'))\n",
    "    \n",
    "data_all, output_all = mode.predict(device, net, seq_list) \n",
    "# if (transform==True):\n",
    "#     output_tmp = torch.tensor(output_all)\n",
    "#     for n in range(division):\n",
    "#         if (n==0):\n",
    "#             output_all = output_tmp[n::division, :192]\n",
    "#         elif (n==division-1):\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:]], dim=1)\n",
    "#         else:\n",
    "#             output_all = torch.cat([output_all, output_tmp[n::division, 64:192]], dim=1)\n",
    "    \n",
    "#     data_all = input_init.numpy()\n",
    "#     output_all = output_all.numpy()\n",
    "    \n",
    "np.savetxt('accessibility_output.txt', output_all, fmt='%.3f')\n",
    "finish = time.time()\n",
    "datePrint('予測時間', (finish-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample作成\n",
    "path = \"../data/RF01210/RF01210.fa\"\n",
    "\n",
    "with open(path, mode = 'r', encoding = 'utf-8') as f:\n",
    "    seq_file = f.read().splitlines()\n",
    "indexes = [i for i, n in enumerate(seq_file) if n.startswith('>')]\n",
    "\n",
    "for i in range(len(indexes)-1):\n",
    "    with open(f\"../data/RF01210/sample_{i}.txt\", mode=\"w\") as f:\n",
    "        f.write(seq_file[indexes[i]] + \"\\n\")\n",
    "        f.write(''.join(seq_file[indexes[i]+1:indexes[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# castしちゃう\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "for cond, cnt in ((\"train\", 500000), (\"test\", 500000)):\n",
    "    data_path = Path(f\"../data/makedata/{cond}\")\n",
    "    input_array = []\n",
    "    target_array = []\n",
    "    print(f\"reading {cond} files\")\n",
    "    for i in tqdm(range(cnt)):\n",
    "        input_path = data_path / f\"index/input_{i+1}.csv\"\n",
    "        target_path = data_path / f\"accessibility/target_{i+1}.csv\"\n",
    "\n",
    "        input_array.append(torch.Tensor(np.loadtxt(input_path, delimiter=\",\", dtype=np.float).astype(np.int)))\n",
    "        target_array.append(torch.Tensor(np.loadtxt(target_path, delimiter=\",\", dtype=np.float)))\n",
    "    print(f\"saving to input_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(input_array), open(f\"../data/input_{cond}.pkl\", 'wb'))\n",
    "        \n",
    "    print(f\"saving to target_{cond}.pkl\")\n",
    "    pickle.dump(torch.stack(target_array), open(f\"../data/target_{cond}.pkl\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [
    {
     "file_id": "1ir0IJd6vc8l_FMQY9-YSFWxAQiIxZF6p",
     "timestamp": 1591723758584
    },
    {
     "file_id": "1cSw8tGp7_Atz1RUom-WbFEdJ1yVDgKCC",
     "timestamp": 1591700460320
    },
    {
     "file_id": "1-iiGLGF3JfbxpJ5cz5GyMTmbOMxhDH6D",
     "timestamp": 1591434878746
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16b98715895a42739075b7711e0ba437": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee0ab1bbc1e4cada381cdadbc3dc5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c5b3c652eab41459f3779503ab44717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b98715895a42739075b7711e0ba437",
      "placeholder": "​",
      "style": "IPY_MODEL_2ee0ab1bbc1e4cada381cdadbc3dc5f2",
      "value": " 0/50 [00:00&lt;?, ?it/s]"
     }
    },
    "4d55df15f3f947888809d424885dfe55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a817f317b5c42f592f130f576ee3063",
       "IPY_MODEL_3c5b3c652eab41459f3779503ab44717"
      ],
      "layout": "IPY_MODEL_a3ed74bd975e4e87955a0de33c520916"
     }
    },
    "5098cf4e3a6a4e5fb9daec2f6dc59c9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a817f317b5c42f592f130f576ee3063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5098cf4e3a6a4e5fb9daec2f6dc59c9d",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de9d1fa4cee24559a816afe706b91081",
      "value": 0
     }
    },
    "a3ed74bd975e4e87955a0de33c520916": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de9d1fa4cee24559a816afe706b91081": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
