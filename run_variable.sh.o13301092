Warning: no access to tty (Bad file descriptor).
Thus no job control in this shell.
[2021/06/24 19:22:57] loading pickle data
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Embedding-1               [-1, 512, 5]              25
            Conv1d-2              [-1, 64, 512]           1,600
       BatchNorm1d-3              [-1, 64, 512]             128
              ReLU-4              [-1, 64, 512]               0
conv1DBatchNormRelu-5              [-1, 64, 512]               0
            Conv1d-6              [-1, 64, 512]          20,480
       BatchNorm1d-7              [-1, 64, 512]             128
              ReLU-8              [-1, 64, 512]               0
conv1DBatchNormRelu-9              [-1, 64, 512]               0
           Conv1d-10              [-1, 64, 512]          20,480
      BatchNorm1d-11              [-1, 64, 512]             128
             ReLU-12              [-1, 64, 512]               0
conv1DBatchNormRelu-13              [-1, 64, 512]               0
           Conv1d-14              [-1, 64, 512]          20,480
      BatchNorm1d-15              [-1, 64, 512]             128
             ReLU-16              [-1, 64, 512]               0
conv1DBatchNormRelu-17              [-1, 64, 512]               0
           Conv1d-18              [-1, 64, 512]          20,480
      BatchNorm1d-19              [-1, 64, 512]             128
             ReLU-20              [-1, 64, 512]               0
conv1DBatchNormRelu-21              [-1, 64, 512]               0
           Conv1d-22              [-1, 64, 512]          20,480
      BatchNorm1d-23              [-1, 64, 512]             128
             ReLU-24              [-1, 64, 512]               0
conv1DBatchNormRelu-25              [-1, 64, 512]               0
           Conv1d-26              [-1, 64, 512]          20,480
      BatchNorm1d-27              [-1, 64, 512]             128
             ReLU-28              [-1, 64, 512]               0
conv1DBatchNormRelu-29              [-1, 64, 512]               0
           Conv1d-30              [-1, 64, 512]          20,480
      BatchNorm1d-31              [-1, 64, 512]             128
             ReLU-32              [-1, 64, 512]               0
conv1DBatchNormRelu-33              [-1, 64, 512]               0
           Conv1d-34              [-1, 64, 512]          20,480
      BatchNorm1d-35              [-1, 64, 512]             128
             ReLU-36              [-1, 64, 512]               0
conv1DBatchNormRelu-37              [-1, 64, 512]               0
           Conv1d-38              [-1, 64, 512]          20,480
      BatchNorm1d-39              [-1, 64, 512]             128
             ReLU-40              [-1, 64, 512]               0
conv1DBatchNormRelu-41              [-1, 64, 512]               0
           Conv1d-42              [-1, 64, 512]          20,480
      BatchNorm1d-43              [-1, 64, 512]             128
             ReLU-44              [-1, 64, 512]               0
conv1DBatchNormRelu-45              [-1, 64, 512]               0
           Conv1d-46              [-1, 64, 512]          20,480
      BatchNorm1d-47              [-1, 64, 512]             128
             ReLU-48              [-1, 64, 512]               0
conv1DBatchNormRelu-49              [-1, 64, 512]               0
           Conv1d-50              [-1, 64, 512]          20,480
      BatchNorm1d-51              [-1, 64, 512]             128
             ReLU-52              [-1, 64, 512]               0
conv1DBatchNormRelu-53              [-1, 64, 512]               0
           Conv1d-54              [-1, 64, 512]          20,480
      BatchNorm1d-55              [-1, 64, 512]             128
             ReLU-56              [-1, 64, 512]               0
conv1DBatchNormRelu-57              [-1, 64, 512]               0
           Conv1d-58              [-1, 64, 512]          20,480
      BatchNorm1d-59              [-1, 64, 512]             128
             ReLU-60              [-1, 64, 512]               0
conv1DBatchNormRelu-61              [-1, 64, 512]               0
           Conv1d-62              [-1, 64, 512]          20,480
      BatchNorm1d-63              [-1, 64, 512]             128
             ReLU-64              [-1, 64, 512]               0
conv1DBatchNormRelu-65              [-1, 64, 512]               0
           Conv1d-66               [-1, 1, 508]             321
================================================================
Total params: 311,194
Trainable params: 311,194
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 16.02
Params size (MB): 1.19
Estimated Total Size (MB): 17.21
----------------------------------------------------------------
Epoch 1/20
train Loss:2.5845 Timer:438.4706
val Loss:2.4472 Timer:12.6291
Epoch 2/20
train Loss:2.3595 Timer:435.3186
val Loss:2.2808 Timer:11.8288
Epoch 3/20
train Loss:2.2240 Timer:441.6141
val Loss:2.1838 Timer:11.7457
Epoch 4/20
train Loss:2.1413 Timer:431.1858
val Loss:2.1136 Timer:11.8818
Epoch 5/20
train Loss:2.0872 Timer:431.5368
val Loss:2.0676 Timer:18.3752
Epoch 6/20
train Loss:2.0481 Timer:432.7612
val Loss:2.0352 Timer:11.9776
Epoch 7/20
train Loss:2.0181 Timer:431.9612
val Loss:2.0082 Timer:11.9052
Epoch 8/20
train Loss:1.9943 Timer:435.2264
val Loss:1.9880 Timer:12.0670
Epoch 9/20
train Loss:1.9755 Timer:436.4836
val Loss:1.9731 Timer:11.9540
Epoch 10/20
train Loss:1.9599 Timer:432.9788
val Loss:1.9610 Timer:19.0845
Epoch 11/20
train Loss:1.9468 Timer:435.5477
val Loss:1.9466 Timer:11.7978
Epoch 12/20
train Loss:1.9356 Timer:431.6326
val Loss:1.9362 Timer:11.7110
Epoch 13/20
train Loss:1.9258 Timer:430.1632
val Loss:1.9274 Timer:11.7530
Epoch 14/20
train Loss:1.9172 Timer:433.5182
val Loss:1.9192 Timer:11.7580
Epoch 15/20
train Loss:1.9095 Timer:438.0700
val Loss:1.9099 Timer:19.7423
Epoch 16/20
train Loss:1.9029 Timer:439.9486
val Loss:1.9107 Timer:11.8482
Epoch 17/20
train Loss:1.8969 Timer:464.0354
val Loss:1.9007 Timer:12.3008
Epoch 18/20
train Loss:1.8914 Timer:463.8444
val Loss:1.8936 Timer:13.5003
Epoch 19/20
train Loss:1.8865 Timer:469.7545
val Loss:1.8900 Timer:12.0306
Epoch 20/20
train Loss:1.8819 Timer:463.2761
val Loss:1.8853 Timer:19.9759
